#!/usr/bin/env python3
"""
ä¸‹è½½å‘é‡æ•°æ®åº“æ–‡ä»¶
æ”¯æŒä»äº‘å­˜å‚¨ï¼ˆS3/é˜¿é‡Œäº‘ OSSï¼‰æˆ– HTTP URL ä¸‹è½½
"""

import os
import sys
from pathlib import Path
import requests
from tqdm import tqdm
import argparse

PROJECT_ROOT = Path(__file__).parent.parent
EMBEDDINGS_DIR = PROJECT_ROOT / "data" / "embeddings"


def download_file(url: str, dest_path: Path, desc: str = "Downloading"):
    """
    ä» URL ä¸‹è½½æ–‡ä»¶ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡

    Args:
        url: æ–‡ä»¶ URL
        dest_path: ä¿å­˜è·¯å¾„
        desc: è¿›åº¦æ¡æè¿°
    """
    print(f"ğŸ“¥ {desc}: {url}")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    dest_path.parent.mkdir(parents=True, exist_ok=True)

    # ä¸‹è½½æ–‡ä»¶
    response = requests.get(url, stream=True)
    response.raise_for_status()

    # è·å–æ–‡ä»¶å¤§å°
    total_size = int(response.headers.get('content-length', 0))

    # å†™å…¥æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦
    with open(dest_path, 'wb') as f, tqdm(
        desc=desc,
        total=total_size,
        unit='iB',
        unit_scale=True,
        unit_divisor=1024,
    ) as pbar:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                pbar.update(len(chunk))

    print(f"âœ… å·²ä¿å­˜åˆ°: {dest_path}")


def download_from_s3(bucket: str, prefix: str, region: str = "us-east-1"):
    """
    ä» AWS S3 ä¸‹è½½å‘é‡æ•°æ®åº“æ–‡ä»¶

    Args:
        bucket: S3 bucket åç§°
        prefix: S3 å¯¹è±¡å‰ç¼€
        region: AWS åŒºåŸŸ
    """
    try:
        import boto3

        s3 = boto3.client('s3', region_name=region)

        # ä¸‹è½½ FAISS ç´¢å¼•
        faiss_key = f"{prefix}/faiss_index_robust_5x.bin"
        faiss_path = EMBEDDINGS_DIR / "faiss_index_robust_5x.bin"

        print(f"ğŸ“¥ ä» S3 ä¸‹è½½ FAISS ç´¢å¼•: s3://{bucket}/{faiss_key}")
        s3.download_file(bucket, faiss_key, str(faiss_path))
        print(f"âœ… å·²ä¿å­˜åˆ°: {faiss_path}")

        # ä¸‹è½½å…ƒæ•°æ®
        metadata_key = f"{prefix}/sku_metadata_robust_5x.pkl"
        metadata_path = EMBEDDINGS_DIR / "sku_metadata_robust_5x.pkl"

        print(f"ğŸ“¥ ä» S3 ä¸‹è½½å…ƒæ•°æ®: s3://{bucket}/{metadata_key}")
        s3.download_file(bucket, metadata_key, str(metadata_path))
        print(f"âœ… å·²ä¿å­˜åˆ°: {metadata_path}")

        print("\nâœ… å‘é‡æ•°æ®åº“ä¸‹è½½å®Œæˆï¼")

    except ImportError:
        print("âŒ é”™è¯¯: boto3 æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install boto3")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ S3 ä¸‹è½½å¤±è´¥: {e}")
        sys.exit(1)


def download_from_http(base_url: str):
    """
    ä» HTTP URL ä¸‹è½½å‘é‡æ•°æ®åº“æ–‡ä»¶

    Args:
        base_url: åŸºç¡€ URLï¼ˆä¸åŒ…å«æ–‡ä»¶åï¼‰
    """
    try:
        # ä¸‹è½½ FAISS ç´¢å¼•
        faiss_url = f"{base_url}/faiss_index_robust_5x.bin"
        faiss_path = EMBEDDINGS_DIR / "faiss_index_robust_5x.bin"
        download_file(faiss_url, faiss_path, "ä¸‹è½½ FAISS ç´¢å¼•")

        # ä¸‹è½½å…ƒæ•°æ®
        metadata_url = f"{base_url}/sku_metadata_robust_5x.pkl"
        metadata_path = EMBEDDINGS_DIR / "sku_metadata_robust_5x.pkl"
        download_file(metadata_url, metadata_path, "ä¸‹è½½ SKU å…ƒæ•°æ®")

        print("\nâœ… å‘é‡æ•°æ®åº“ä¸‹è½½å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ HTTP ä¸‹è½½å¤±è´¥: {e}")
        sys.exit(1)


def check_embeddings_exist() -> bool:
    """æ£€æŸ¥å‘é‡æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    faiss_path = EMBEDDINGS_DIR / "faiss_index_robust_5x.bin"
    metadata_path = EMBEDDINGS_DIR / "sku_metadata_robust_5x.pkl"

    return faiss_path.exists() and metadata_path.exists()


def main():
    parser = argparse.ArgumentParser(description="ä¸‹è½½å‘é‡æ•°æ®åº“æ–‡ä»¶")
    parser.add_argument(
        "--source",
        choices=["s3", "http"],
        required=True,
        help="ä¸‹è½½æºç±»å‹"
    )
    parser.add_argument(
        "--s3-bucket",
        help="S3 bucket åç§°ï¼ˆå½“ source=s3 æ—¶å¿…éœ€ï¼‰"
    )
    parser.add_argument(
        "--s3-prefix",
        default="embeddings",
        help="S3 å¯¹è±¡å‰ç¼€ï¼ˆé»˜è®¤: embeddingsï¼‰"
    )
    parser.add_argument(
        "--s3-region",
        default="us-east-1",
        help="AWS åŒºåŸŸï¼ˆé»˜è®¤: us-east-1ï¼‰"
    )
    parser.add_argument(
        "--http-url",
        help="HTTP åŸºç¡€ URLï¼ˆå½“ source=http æ—¶å¿…éœ€ï¼‰"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå³ä½¿æ–‡ä»¶å·²å­˜åœ¨ï¼‰"
    )

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if check_embeddings_exist() and not args.force:
        print("â„¹ï¸  å‘é‡æ•°æ®åº“æ–‡ä»¶å·²å­˜åœ¨")
        print(f"   FAISS ç´¢å¼•: {EMBEDDINGS_DIR / 'faiss_index_robust_5x.bin'}")
        print(f"   SKU å…ƒæ•°æ®: {EMBEDDINGS_DIR / 'sku_metadata_robust_5x.pkl'}")
        print("\nå¦‚éœ€é‡æ–°ä¸‹è½½ï¼Œè¯·ä½¿ç”¨ --force å‚æ•°")
        return

    # æ ¹æ®æºç±»å‹ä¸‹è½½
    if args.source == "s3":
        if not args.s3_bucket:
            print("âŒ é”™è¯¯: --s3-bucket å‚æ•°å¿…éœ€")
            sys.exit(1)
        download_from_s3(args.s3_bucket, args.s3_prefix, args.s3_region)

    elif args.source == "http":
        if not args.http_url:
            print("âŒ é”™è¯¯: --http-url å‚æ•°å¿…éœ€")
            sys.exit(1)
        download_from_http(args.http_url)


if __name__ == "__main__":
    main()
